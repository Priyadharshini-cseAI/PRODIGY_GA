# -*- coding: utf-8 -*-
"""PRODIGY_GA_05.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14dnNioUfpTO7v_8mNqSTDpbN-lDgzjdk
"""

import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import requests
from io import BytesIO


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def load_image(url, size=512):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        image = Image.open(BytesIO(response.content)).convert('RGB')
        image = image.resize((size, size))
        transform = transforms.ToTensor()
        return transform(image).unsqueeze(0).to(device)
    except Exception as e:
        print(f"Error loading image from {url}: {e}")
        return None


content_url = "https://images.unsplash.com/photo-1502082553048-f009c37129b9"
style_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Mona_Lisa%2C_by_Leonardo_da_Vinci%2C_from_C2RMF_retouched.jpg/402px-Mona_Lisa%2C_by_Leonardo_da_Vinci%2C_from_C2RMF_retouched.jpg"  # Example style image


content_img = load_image(content_url)
style_img = load_image(style_url)

if content_img is None or style_img is None:
    print("Failed to load one or both images. Please check the URLs.")
else:

    cnn = models.vgg19(pretrained=True).features.to(device).eval()


    def gram_matrix(x):
        b, c, h, w = x.size()
        features = x.view(c, h * w)
        return torch.mm(features, features.t()) / (c * h * w)

    class ContentLoss(nn.Module):
        def __init__(self, target): super().__init__(); self.target = target.detach()
        def forward(self, x): self.loss = nn.functional.mse_loss(x, self.target); return x

    class StyleLoss(nn.Module):
        def __init__(self, target): super().__init__(); self.target = gram_matrix(target).detach()
        def forward(self, x): self.loss = nn.functional.mse_loss(gram_matrix(x), self.target); return x

    def get_model(cnn, style_img, content_img):
        content_layers = ['conv_4']
        style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']
        model = nn.Sequential().to(device)
        c_losses, s_losses = [], []
        i = 0
        for layer in cnn.children():
            if isinstance(layer, nn.Conv2d): i += 1; name = f'conv_{i}'
            elif isinstance(layer, nn.ReLU): name = f'relu_{i}'; layer = nn.ReLU(inplace=False)
            elif isinstance(layer, nn.MaxPool2d): name = f'pool_{i}'
            elif isinstance(layer, nn.BatchNorm2d): name = f'bn_{i}'
            else: continue
            model.add_module(name, layer)
            if name in content_layers:
                tgt = model(content_img).detach()
                cl = ContentLoss(tgt); model.add_module(f"content_loss_{i}", cl); c_losses.append(cl)
            if name in style_layers:
                tgt = model(style_img).detach()
                sl = StyleLoss(tgt); model.add_module(f"style_loss_{i}", sl); s_losses.append(sl)
        for i in range(len(model)-1, -1, -1):
            if isinstance(model[i], (ContentLoss, StyleLoss)): break
        return model[:(i+1)], s_losses, c_losses


    input_img = content_img.clone().requires_grad_(True)
    model, style_losses, content_losses = get_model(cnn, style_img, content_img)
    optimizer = torch.optim.LBFGS([input_img])

    print("ðŸ§  Running style transfer...")
    steps = 300
    run = [0]
    while run[0] <= steps:
        def closure():
            optimizer.zero_grad()
            model(input_img)
            style_score = sum(sl.loss for sl in style_losses)
            content_score = sum(cl.loss for cl in content_losses)
            loss = style_score * 1e6 + content_score
            loss.backward()
            run[0] += 1
            if run[0] % 50 == 0:
                print(f"Step {run[0]} - Style Loss: {style_score.item():.4f}, Content Loss: {content_score.item():.4f}")
            return loss
        optimizer.step(closure)

    out = input_img.cpu().detach().squeeze(0)
    result = transforms.ToPILImage()(out)
    plt.imshow(result)
    plt.axis('off')
    plt.title("Stylized Image")
    plt.show()

    result.save("stylized_output.jpg")
    files.download("stylized_output.jpg")